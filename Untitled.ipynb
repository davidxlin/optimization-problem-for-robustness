{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed8e7d10-a07c-4a77-aec0-427b498e1113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[COARSE] best = SearchResult(p1=1.3355330075307468, p2=1.7772731407948512, p3=2.218036576184923, value=0.6248318783338377, evals=9370361000, seconds=306.56154729193076)\n",
      "[REFINED] best = SearchResult(p1=1.3333405651175934, p2=1.7777870802916789, p3=2.2222049339278165, value=0.6249967057055402, evals=21640541000, seconds=585.4742142501054)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "# -------------------- Domain bounds --------------------\n",
    "\n",
    "# p1 ∈ [0, 2e], p2 ∈ [0, 4e], p3 ∈ [0, 12e]\n",
    "P1_MAX = 2.0 * math.e\n",
    "P2_MAX = 4.0 * math.e\n",
    "P3_MAX = 12.0 * math.e\n",
    "\n",
    "EPS = 1e-15  # tolerance for zero checks and numeric stability\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SearchResult:\n",
    "    p1: float\n",
    "    p2: float\n",
    "    p3: float\n",
    "    value: float\n",
    "    evals: int\n",
    "    seconds: float\n",
    "\n",
    "\n",
    "# -------------------- Utilities for A_k and B_k --------------------\n",
    "\n",
    "def A_k(gamma, k: int):\n",
    "    \"\"\"\n",
    "    A_k(gamma) = gamma/(1+k) + (1 - gamma) = 1 - (k/(k+1))*gamma\n",
    "    Works with scalars or numpy arrays.\n",
    "    \"\"\"\n",
    "    return 1.0 - (k / (k + 1.0)) * gamma\n",
    "def B_k(p1: float, pkplus_over: np.ndarray | float, gamma: np.ndarray | float):\n",
    "    \"\"\"\n",
    "    B_k(gamma) = min(1, 1 / ( (p_{k+1}/(k+1)) * gamma + p1 * (1 - gamma)) ).\n",
    "\n",
    "    Note: denom = p1 + gamma*(pkplus_over - p1), which for p1>=0, pkplus_over>=0 and gamma ∈ [0,1]\n",
    "    is a convex combination of p1 and pkplus_over, hence nonnegative.\n",
    "    If denom == 0 (only when p1=pkplus_over=0), we set 1/denom = +inf, so min(1, +inf) = 1.\n",
    "    \"\"\"\n",
    "    denom = p1 + gamma * (pkplus_over - p1)\n",
    "    if isinstance(denom, np.ndarray):\n",
    "        inv = np.empty_like(denom, dtype=float)\n",
    "        mask_zero = np.isclose(denom, 0.0, atol=EPS)\n",
    "        inv[mask_zero] = np.inf\n",
    "        inv[~mask_zero] = 1.0 / denom[~mask_zero]\n",
    "        return np.minimum(1.0, inv)\n",
    "    else:\n",
    "        if abs(denom) <= EPS:\n",
    "            return 1.0\n",
    "        return min(1.0, 1.0 / denom)\n",
    "\n",
    "\n",
    "# -------------------- Lower bounds and gamma candidates --------------------\n",
    "\n",
    "def lower_bound_Lk_scalar(p1: float, pk: float, pkplus_over: float) -> float:\n",
    "    \"\"\"\n",
    "    L_k = min(1, max{ 1/p_k, p1 / (p_k - pkplus_over + p1) })\n",
    "    Scalar version for k=1.\n",
    "    \"\"\"\n",
    "    # Handle 1/pk\n",
    "    if pk <= 0.0:\n",
    "        term1 = float('inf')\n",
    "    else:\n",
    "        term1 = 1.0 / pk\n",
    "    denom = pk - pkplus_over + p1\n",
    "    if abs(denom) <= EPS:\n",
    "        term2 = float('inf')\n",
    "    else:\n",
    "        term2 = p1 / denom\n",
    "\n",
    "    Lk = min(1.0, max(term1, term2))\n",
    "    # clamp to [0,1]\n",
    "    if Lk < 0.0:\n",
    "        Lk = 0.0\n",
    "    elif Lk > 1.0:\n",
    "        Lk = 1.0\n",
    "    return Lk\n",
    "\n",
    "\n",
    "def lower_bound_Lk_vec(p1: float, pk: float, pkplus_over_vec: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    L_k = min(1, max{ 1/p_k, p1 / (p_k - pkplus_over + p1) })\n",
    "    Vectorized over pkplus_over (used for k=2 with varying p3).\n",
    "    \"\"\"\n",
    "    if pk <= 0.0:\n",
    "        term1 = np.inf\n",
    "    else:\n",
    "        term1 = 1.0 / pk\n",
    "\n",
    "    denom = pk - pkplus_over_vec + p1\n",
    "    term2 = np.empty_like(denom, dtype=float)\n",
    "    mask_zero = np.isclose(denom, 0.0, atol=EPS)\n",
    "    term2[mask_zero] = np.inf\n",
    "    term2[~mask_zero] = p1 / denom[~mask_zero]\n",
    "\n",
    "    Lk = np.minimum(1.0, np.maximum(term1, term2))\n",
    "    np.clip(Lk, 0.0, 1.0, out=Lk)\n",
    "    return Lk\n",
    "\n",
    "\n",
    "def gamma1_candidate_scalar(p1: float, pk: float, pkplus_over: float, k: int) -> float:\n",
    "    \"\"\"\n",
    "    gamma^(1)_k = min(1, max{ 1/(p_k * k), p1 / (p_k - pkplus_over + p1) })\n",
    "    Scalar version (used for k=1).\n",
    "    \"\"\"\n",
    "    if pk <= 0.0:\n",
    "        term1 = float('inf')\n",
    "    else:\n",
    "        term1 = 1.0 / (pk * k)\n",
    "\n",
    "    denom = pk - pkplus_over + p1\n",
    "    if abs(denom) <= EPS:\n",
    "        term2 = float('inf')\n",
    "    else:\n",
    "        term2 = p1 / denom\n",
    "\n",
    "    g1 = min(1.0, max(term1, term2))\n",
    "    # ensure [0,1]\n",
    "    if g1 < 0.0:\n",
    "        g1 = 0.0\n",
    "    elif g1 > 1.0:\n",
    "        g1 = 1.0\n",
    "    return g1\n",
    "\n",
    "\n",
    "def gamma1_candidate_vec(p1: float, pk: float, pkplus_over_vec: np.ndarray, k: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Vectorized gamma^(1)_k over pkplus_over_vec (used for k=2).\n",
    "    \"\"\"\n",
    "    if pk <= 0.0:\n",
    "        term1 = np.inf\n",
    "    else:\n",
    "        term1 = 1.0 / (pk * k)\n",
    "\n",
    "    denom = pk - pkplus_over_vec + p1\n",
    "    term2 = np.empty_like(denom, dtype=float)\n",
    "    mask_zero = np.isclose(denom, 0.0, atol=EPS)\n",
    "    term2[mask_zero] = np.inf\n",
    "    term2[~mask_zero] = p1 / denom[~mask_zero]\n",
    "\n",
    "    g1 = np.minimum(1.0, np.maximum(term1, term2))\n",
    "    np.clip(g1, 0.0, 1.0, out=g1)\n",
    "    return g1\n",
    "\n",
    "\n",
    "def gamma2_candidate_scalar(p1: float, pkplus_over: float) -> Optional[float]:\n",
    "    \"\"\"\n",
    "    gamma^(2)_k = p1 / (pkplus_over - p1), if denominator != 0, else None.\n",
    "    \"\"\"\n",
    "    denom = pkplus_over - p1\n",
    "    if abs(denom) <= EPS:\n",
    "        return None\n",
    "    return p1 / denom\n",
    "\n",
    "\n",
    "def gamma2_candidate_vec(p1: float, pkplus_over_vec: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Vectorized gamma^(2)_k over pkplus_over_vec.\n",
    "    Returns array with NaNs where undefined (denominator near zero).\n",
    "    \"\"\"\n",
    "    denom = pkplus_over_vec - p1\n",
    "    g2 = np.full_like(pkplus_over_vec, np.nan, dtype=float)\n",
    "    mask = ~np.isclose(denom, 0.0, atol=EPS)\n",
    "    g2[mask] = p1 / denom[mask]\n",
    "    return g2\n",
    "\n",
    "\n",
    "# -------------------- mu(p1,p2,p3,k): max over feasible candidates --------------------\n",
    "\n",
    "def mu_k1(p1: float, p2: float) -> float:\n",
    "    \"\"\"\n",
    "    k=1:\n",
    "      pk = p1\n",
    "      pkplus_over = p2/(1+1) = p2/2\n",
    "      L1 = min(1, max{ 1/p1, p1/(p1 - p2/2 + p1) })\n",
    "      candidates: gamma1 = min(1, max{ 1/(p1*1), p1/(p1 - p2/2 + p1) })\n",
    "                  gamma2 = p1 / (p2/2 - p1)  (if defined)\n",
    "      feasible if gamma ∈ [L1, 1].\n",
    "    \"\"\"\n",
    "    pk = p1\n",
    "    pkplus_over = p2 / 2.0\n",
    "    L1 = lower_bound_Lk_scalar(p1, pk, pkplus_over)\n",
    "\n",
    "    # Candidate 1\n",
    "    g1 = gamma1_candidate_scalar(p1, pk, pkplus_over, k=1)\n",
    "    vals = []\n",
    "\n",
    "    if g1 >= L1 - 1e-15 and g1 <= 1.0 + 1e-15:\n",
    "        val1 = A_k(g1, k=1) * B_k(p1, pkplus_over, g1)\n",
    "        vals.append(val1)\n",
    "\n",
    "    # Candidate 2\n",
    "    g2 = gamma2_candidate_scalar(p1, pkplus_over)\n",
    "    if g2 is not None and g2 >= L1 - 1e-15 and g2 <= 1.0 + 1e-15:\n",
    "        val2 = A_k(g2, k=1) * B_k(p1, pkplus_over, g2)\n",
    "        vals.append(val2)\n",
    "\n",
    "    if not vals:\n",
    "        return -float('inf')\n",
    "    return max(vals)\n",
    "\n",
    "\n",
    "def mu_k2_vec(p1: float, p2: float, p3_vals: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    k=2 (vectorized across p3_vals):\n",
    "      pk = p2\n",
    "      pkplus_over = p3/(1+2) = p3/3\n",
    "      L2 = min(1, max{ 1/p2, p1/(p2 - p3/3 + p1) })\n",
    "      candidates: gamma1 = min(1, max{ 1/(p2*2), p1/(p2 - p3/3 + p1) })\n",
    "                  gamma2 = p1 / (p3/3 - p1)  (if defined)\n",
    "      feasible if gamma ∈ [L2, 1].\n",
    "    \"\"\"\n",
    "    pk = p2\n",
    "    pkplus_over = p3_vals / 3.0\n",
    "\n",
    "    L2 = lower_bound_Lk_vec(p1, pk, pkplus_over)\n",
    "\n",
    "    # Candidate 1 (vectorized)\n",
    "    g1 = gamma1_candidate_vec(p1, pk, pkplus_over, k=2)\n",
    "    val1 = A_k(g1, k=2) * B_k(p1, pkplus_over, g1)\n",
    "    feas1 = (g1 >= L2 - 1e-15) & (g1 <= 1.0 + 1e-15)\n",
    "    val1[~feas1] = -np.inf\n",
    "    # Candidate 2 (vectorized)\n",
    "    g2 = gamma2_candidate_vec(p1, pkplus_over)\n",
    "    feas2 = ~np.isnan(g2)\n",
    "    # Enforce feasibility band [L2, 1]\n",
    "    feas2 = feas2 & (g2 >= L2 - 1e-15) & (g2 <= 1.0 + 1e-15)\n",
    "    val2 = np.full_like(p3_vals, -np.inf, dtype=float)\n",
    "    if np.any(feas2):\n",
    "        val2[feas2] = A_k(g2[feas2], k=2) * B_k(p1, pkplus_over[feas2], g2[feas2])\n",
    "\n",
    "    # Take max across feasible candidates\n",
    "    return np.maximum(val1, val2)\n",
    "\n",
    "\n",
    "# -------------------- Brute-force search over (p1, p2, p3) --------------------\n",
    "\n",
    "def brute_force_search(\n",
    "    steps_p1: int = 121,\n",
    "    steps_p2: int = 161,\n",
    "    steps_p3: int = 481,\n",
    "    p1_max: float = P1_MAX,\n",
    "    p2_max: float = P2_MAX,\n",
    "    p3_max: float = P3_MAX,\n",
    ") -> SearchResult:\n",
    "    \"\"\"\n",
    "    Brute-force on a rectilinear grid.\n",
    "    Returns the best (p1, p2, p3) and the objective value:\n",
    "        obj(p1,p2,p3) = min( mu_k1, mu_k2 )\n",
    "    \"\"\"\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    p1_vals = np.linspace(0.0, p1_max, steps_p1)\n",
    "    p2_vals = np.linspace(0.0, p2_max, steps_p2)\n",
    "    p3_vals = np.linspace(0.0, p3_max, steps_p3)\n",
    "\n",
    "    best_val = -float('inf')\n",
    "    best_tuple: Optional[Tuple[float, float, float]] = None\n",
    "    evals = 0\n",
    "\n",
    "    for p1 in p1_vals:\n",
    "        for p2 in p2_vals:\n",
    "            # k=1 term (scalar for this (p1,p2))\n",
    "            mu1 = mu_k1(p1, p2)\n",
    "\n",
    "            # k=2 term (vectorized across all p3)\n",
    "            mu2_vec = mu_k2_vec(p1, p2, p3_vals)\n",
    "\n",
    "            # Overall objective at each p3 is min over k\n",
    "            obj_vec = np.minimum(mu1, mu2_vec)\n",
    "\n",
    "            idx = int(np.argmax(obj_vec))\n",
    "            cand_val = float(obj_vec[idx])\n",
    "            cand_p3 = float(p3_vals[idx])\n",
    "\n",
    "            evals += len(p3_vals)\n",
    "\n",
    "            if cand_val > best_val:\n",
    "                best_val = cand_val\n",
    "                best_tuple = (float(p1), float(p2), cand_p3)\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "\n",
    "    assert best_tuple is not None\n",
    "    return SearchResult(\n",
    "        p1=best_tuple[0],\n",
    "        p2=best_tuple[1],\n",
    "        p3=best_tuple[2],\n",
    "        value=best_val,\n",
    "        evals=evals,\n",
    "        seconds=(t1 - t0),\n",
    "    )\n",
    "\n",
    "\n",
    "def refine_around_best(\n",
    "    best: SearchResult,\n",
    "    span_steps: Tuple[int, int, int] = (6, 8, 12),\n",
    "    refine_steps: Tuple[int, int, int] = (181, 221, 541),\n",
    "    p1_max: float = P1_MAX,\n",
    "    p2_max: float = P2_MAX,\n",
    "    p3_max: float = P3_MAX,\n",
    "    coarse_steps: Tuple[int, int, int] = (121, 161, 481),\n",
    ") -> SearchResult:\n",
    "    \"\"\"\n",
    "    Local refinement around the best coarse point: define a window covering roughly ±span_steps\n",
    "    coarse-grid increments on each axis and resample it at a finer 'refine_steps' resolution.\n",
    "    \"\"\"\n",
    "    (c1, c2, c3) = coarse_steps\n",
    "    (s1, s2, s3) = span_steps\n",
    "    (r1, r2, r3) = refine_steps\n",
    "\n",
    "    def window(best_v, s, max_v, c):\n",
    "        step = max_v / max(c - 1, 1)\n",
    "        return max(0.0, best_v - s * step), min(max_v, best_v + s * step)\n",
    "\n",
    "    p1_lo, p1_hi = window(best.p1, s1, p1_max, c1)\n",
    "    p2_lo, p2_hi = window(best.p2, s2, p2_max, c2)\n",
    "    p3_lo, p3_hi = window(best.p3, s3, p3_max, c3)\n",
    "\n",
    "    r1 = max(2, r1)\n",
    "    r2 = max(2, r2)\n",
    "    r3 = max(2, r3)\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    p1_vals = np.linspace(p1_lo, p1_hi, r1)\n",
    "    p2_vals = np.linspace(p2_lo, p2_hi, r2)\n",
    "    p3_vals = np.linspace(p3_lo, p3_hi, r3)\n",
    "\n",
    "    best_val = -float('inf')\n",
    "    best_tuple: Optional[Tuple[float, float, float]] = None\n",
    "    evals = 0\n",
    "\n",
    "    for p1 in p1_vals:\n",
    "        for p2 in p2_vals:\n",
    "            mu1 = mu_k1(p1, p2)\n",
    "            mu2_vec = mu_k2_vec(p1, p2, p3_vals)\n",
    "\n",
    "            obj_vec = np.minimum(mu1, mu2_vec)\n",
    "\n",
    "            idx = int(np.argmax(obj_vec))\n",
    "            cand_val = float(obj_vec[idx])\n",
    "            cand_p3 = float(p3_vals[idx])\n",
    "\n",
    "            evals += len(p3_vals)\n",
    "\n",
    "            if cand_val > best_val:\n",
    "                best_val = cand_val\n",
    "                best_tuple = (float(p1), float(p2), cand_p3)\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "\n",
    "    assert best_tuple is not None\n",
    "    return SearchResult(\n",
    "        p1=best_tuple[0],\n",
    "        p2=best_tuple[1],\n",
    "        p3=best_tuple[2],\n",
    "        value=best_val,\n",
    "        evals=evals,\n",
    "        seconds=(t1 - t0),\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example: a reasonably fine grid to start with (adjust to your time budget).\n",
    "    coarse = brute_force_search(\n",
    "        steps_p1=1210,   # p1 ∈ [0, 2e]\n",
    "        steps_p2=1610,   # p2 ∈ [0, 4e]\n",
    "        steps_p3=4810,   # p3 ∈ [0, 12e]\n",
    "    )\n",
    "    print(\"[COARSE] best =\", coarse)\n",
    "\n",
    "    # Optional: refine around the best coarse point\n",
    "    refined = refine_around_best(\n",
    "        best=coarse,\n",
    "        span_steps=(6, 8, 12),\n",
    "        refine_steps=(1810, 2210, 5410),\n",
    "        coarse_steps=(1210, 1610, 4810),\n",
    "    )\n",
    "    print(\"[REFINED] best =\", refined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89576e0-11c7-4a67-aa69-9c53b2430c24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
